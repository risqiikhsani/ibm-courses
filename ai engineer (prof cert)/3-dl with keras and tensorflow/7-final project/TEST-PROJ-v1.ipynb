{"cells":[{"cell_type":"markdown","id":"773037d1-7dfb-43d8-8ca5-ce5460ef09c3","metadata":{},"outputs":[],"source":["<p style=\"text-align:center\">\n","    <a href=\"https://skills.network\" target=\"_blank\">\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n","    </a>\n","</p>\n"]},{"cell_type":"markdown","id":"508e1409-c90d-496a-a4ca-c05aebeae19f","metadata":{},"outputs":[],"source":["# Practice Project: Fruit Classification Using Transfer Learning \n","**Estimated Time Needed:** 60 minutes\n"]},{"cell_type":"markdown","id":"1fe581f0-4f63-4fb4-a015-cf9ca9ff61d9","metadata":{},"outputs":[],"source":["### Introduction \n","\n","In this lab, you will learn how to classify images of fruits using transfer learning with the pre-trained VGG16 model. Transfer learning enables leveraging a model trained on a large dataset (like ImageNet) and applying it to your dataset with fewer data and computational resources.\n"]},{"cell_type":"markdown","id":"e7442e5a-a2dc-4c5d-bb70-c76212f82351","metadata":{},"outputs":[],"source":["### Aim \n","\n","The aim is to build a fruit image classifier using transfer learning. You will fine-tune a pre-trained model on a custom dataset of fruit images to enable it to classify fruits effectively.\n"]},{"cell_type":"markdown","id":"88bde35c-412c-489e-ba91-fa1916a62c76","metadata":{},"outputs":[],"source":["### Final output \n","\n","The final output will be a trained deep learning model capable of classifying various fruit images into their respective categories. You will also visualize the model's accuracy and predictions on sample test images.\n"]},{"cell_type":"markdown","id":"7842a1f3-bd07-48bd-a473-2e21216499d4","metadata":{},"outputs":[],"source":["### Learning objectives\n","At the end of the project, you will be able to:\n","- Set up and organize a complex fruit image dataset.\n","- Use transfer learning with the VGG16 model.\n","- Fine-tune a pre-trained model for your dataset.\n","- Evaluate and interpret the model’s performance on unseen data.\n"]},{"cell_type":"markdown","id":"d7b16250-f194-496a-99a8-9c6d0220d2be","metadata":{},"outputs":[],"source":["### Setup instructions \n"]},{"cell_type":"markdown","id":"2a37cc43-5607-4101-b507-5edfbfdc6514","metadata":{},"outputs":[],"source":["#### Prerequisites \n","\n","- Basic knowledge of Python and Keras. \n","\n","- TensorFlow installed in your Python environment. \n","\n","- A data set of fruit images organized in subdirectories for each class. \n"]},{"cell_type":"markdown","id":"10b4e8d0-6084-4836-affd-7300ea9cc4fe","metadata":{},"outputs":[],"source":["#### Required libraries \n","\n","Install the following libraries, if you haven't already: \n"]},{"cell_type":"code","id":"25863e60-64d0-4e62-9354-6fe36c5f942a","metadata":{},"outputs":[],"source":["!pip install tensorflow==2.17.0\n!pip install matplotlib==3.9.2\n!pip install numpy==1.26.4\n!pip install scipy==1.14.1\n!pip install scikit-learn==1.5.2\n\n"]},{"cell_type":"markdown","id":"22afc577-b673-4369-82f4-6304ae610cdc","metadata":{},"outputs":[],"source":["### Data preparation \n"]},{"cell_type":"raw","id":"770b0563-4fdb-4bc6-9f0a-5fdbaee624ed","metadata":{},"outputs":[],"source":["Directory structure \n\nEnsure that your data set is organized as follows: \n\n \n\ndata/\n├── train/\n│   ├── Apple/\n│   ├── Banana/\n│   └── Orange/\n├── val/\n│   ├── Apple/\n│   ├── Banana/\n│   └── Orange/\n└── test/\n    ├── Apple/\n    ├── Banana/\n    └── Orange/\n\n \n\nEach subdirectory under train and val should contain images of the respective fruit category. \n"]},{"cell_type":"markdown","id":"909be539-97c0-4a34-958e-95d257587f75","metadata":{},"outputs":[],"source":["### Tasks List\n","To achieve the above objectives, you will complete the following tasks:\n","\n","- Task 1: Import necessary libraries and set dataset paths\n","- Task 2: Set up data generators for training, validation, and testing with augmentation\n","- Task 3: Define the VGG16-based model architecture with custom layers\n","- Task 4: Compile the model with appropriate loss and optimizer\n","- Task 5: Train the model with early stopping and learning rate scheduling\n","- Task 6: Fine-tune the model by unfreezing specific layers in VGG16\n","- Task 7: Evaluate the model on the test set and display accuracy\n","- Task 8: Visualize training performance with accuracy and loss curves\n","- Task 9: Test model predictions on sample images and visualize results\n"]},{"cell_type":"markdown","id":"a2f5faae-08f5-448f-adf2-5f105d2f7b31","metadata":{},"outputs":[],"source":["<h3> Task 1: Import necessary libraries and set dataset paths </h3>\n"]},{"cell_type":"markdown","id":"508a1c9f-84e8-48f2-ac28-95e66be050db","metadata":{},"outputs":[],"source":["**Explanation:** This task involves importing essential libraries and setting up the paths for the dataset directories (train, val, and test). These libraries are necessary for data handling, model building, and performance evaluation.\n"]},{"cell_type":"code","id":"2c27d332-5e17-4dd9-97df-bac4144ebf96","metadata":{},"outputs":[],"source":["import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n\n# Set dataset paths\ntrain_dir = 'fruits-360/Training'\nval_dir = 'fruits-360/Validation'\ntest_dir = 'fruits-360/Test'\n"]},{"cell_type":"markdown","id":"890accf8-dc89-44a9-a7b8-339d5035e4b6","metadata":{},"outputs":[],"source":["### Library Explanations:\n","- `ImageDataGenerator:` For loading images and applying data augmentation.\n","- `VGG16:` Pre-trained model used for transfer learning.\n","- `Sequential:` For building a sequential model.\n","- `Dense, Flatten, Dropout, BatchNormalization:` Layers to customize the model architecture.\n","- `ReduceLROnPlateau, EarlyStopping:` Callbacks for optimizing training.\n"]},{"cell_type":"markdown","id":"4b4fdf26-cf89-404e-8843-a17393702d8d","metadata":{},"outputs":[],"source":["<h3> Task 2: Set up data generators for training, validation, and testing with augmentation </h3>\n"]},{"cell_type":"markdown","id":"9666d9b4-ca3c-419b-9487-d112696fb505","metadata":{},"outputs":[],"source":["**Explanation:** Data generators load images from directories, rescale them, and apply augmentation on the training set to help the model generalize better. Validation and test sets are only rescaled (no augmentation).\n","\n"]},{"cell_type":"code","id":"b2ede7bb-1818-4659-b2cd-54bf42b80f64","metadata":{},"outputs":[],"source":["# Image data generators\ntrain_datagen = ImageDataGenerator(\n    rescale=1.0/255.0,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest'\n)\n\nval_datagen = ImageDataGenerator(rescale=1.0/255.0)\ntest_datagen = ImageDataGenerator(rescale=1.0/255.0)\n\n# Load images from directories\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='categorical'\n)\n\nval_generator = val_datagen.flow_from_directory(\n    val_dir,\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='categorical'\n)\n\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=(150, 150),\n    batch_size=32,\n    class_mode='categorical'\n)\n"]},{"cell_type":"markdown","id":"859cd245-a082-4adf-ad3d-31e3e34bb618","metadata":{},"outputs":[],"source":["### Explanation:\n","- `train_datagen:` Applies rescaling and augmentation (e.g., rotation, zoom) to make the model more robust.\n","- `val_datagen and test_datagen:` Only rescale images for validation/testing.\n","- `flow_from_directory:` Loads images from specified folders into batches for training/validation/testing.\n"]},{"cell_type":"markdown","id":"d27bf9a6-ae8e-43fd-9a4c-56f525fbe1cb","metadata":{},"outputs":[],"source":["<h3>Task 3: Define the VGG16-based model architecture with custom layers</h3>\n"]},{"cell_type":"markdown","id":"952d8b0c-ed81-4bd0-a4d5-67db930205b2","metadata":{},"outputs":[],"source":["**Explanation:** This task involves loading the pre-trained VGG16 model (excluding the top layers) and adding custom layers to adapt it to the fruit classification task.\n","\n"]},{"cell_type":"code","id":"388112bd-77bf-4623-b456-27abca9240ca","metadata":{},"outputs":[],"source":["# Load VGG16 with pre-trained weights\nbase_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n\n# Freeze the base model layers\nfor layer in base_model.layers:\n    layer.trainable = False\n\n# Build the model\nmodel = Sequential([\n    base_model,\n    Flatten(),\n    Dense(256, activation='relu'),\n    BatchNormalization(),\n    Dropout(0.5),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(train_generator.num_classes, activation='softmax')\n])\n"]},{"cell_type":"markdown","id":"9cedf2f0-51a1-4400-b448-ee30b09158c1","metadata":{},"outputs":[],"source":["### Explanation:\n","- `base_model:` Loads VGG16, excluding its dense layers (`include_top=False`).\n","- `for layer in base_model.layers:` Freezes VGG16 layers to retain pre-trained weights.\n","- Custom layers: Flatten the output, then add dense layers with regularization (Dropout) and normalization (BatchNormalization) to enhance learning.\n"]},{"cell_type":"markdown","id":"3a314978-2b09-4751-92a7-1e17068047cb","metadata":{},"outputs":[],"source":["<h3>Task 4: Compile the model with appropriate loss and optimizer</h3>\n"]},{"cell_type":"markdown","id":"0843c452-e857-4d5b-bf44-a8007166edf0","metadata":{},"outputs":[],"source":["**Explanation:** Compile the model to specify the loss function, optimizer, and evaluation metric.\n","\n"]},{"cell_type":"code","id":"5208f002-1405-4366-9941-fc635aa0bc00","metadata":{},"outputs":[],"source":["model.compile(\n    loss='categorical_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy']\n)\n"]},{"cell_type":"markdown","id":"0fe2114a-a666-449c-9f58-ce16f5401525","metadata":{},"outputs":[],"source":["### Explanation:\n","- `categorical_crossentropy:` Used because this is a multi-class classification task.\n","- `adam:` Adaptive learning rate optimizer that helps in faster convergence.\n","- `metrics=['accuracy']:` Tracks model accuracy.\n"]},{"cell_type":"markdown","id":"c77e0616-7644-48f6-af50-f949baa81ce6","metadata":{},"outputs":[],"source":["<h3>Task 5: Train the model with early stopping and learning rate scheduling</h3>\n"]},{"cell_type":"markdown","id":"bc9fef3e-6729-4693-b802-1c16f243f09e","metadata":{},"outputs":[],"source":["**Explanation:** Train the model, using callbacks to monitor the validation loss and adjust the learning rate or stop early to prevent overfitting.\n"]},{"cell_type":"code","id":"eee16536-184a-4da1-93fa-ef5c01e0c6a1","metadata":{},"outputs":[],"source":["# Define callbacks\nlr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-6)\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n# Train the model\nhistory = model.fit(\n    train_generator,\n    epochs=30,\n    validation_data=val_generator,\n    callbacks=[lr_scheduler, early_stopping]\n)\n"]},{"cell_type":"markdown","id":"92de079a-3bf3-4688-ac29-9b1916aa49af","metadata":{},"outputs":[],"source":["### Explanation:\n","- `ReduceLROnPlateau`: Reduces learning rate when validation loss plateaus, allowing better optimization.\n","- `EarlyStopping`: Stops training when validation loss no longer improves, preventing overfitting.\n","- `model.fit`: Trains the model on the `train_generator` and evaluates on `val_generator` each epoch.\n"]},{"cell_type":"markdown","id":"a62320d8-0d5a-45eb-a3b7-caa55f09a280","metadata":{},"outputs":[],"source":["<h3>Task 6: Fine-tune the model by unfreezing specific layers in VGG16</h3>\n"]},{"cell_type":"markdown","id":"351d5231-8dcf-41d6-a39b-645aee7bf7af","metadata":{},"outputs":[],"source":["**Explanation:** Fine-tune by unfreezing a few layers in the VGG16 base model to allow learning on fruit-specific features.\n"]},{"cell_type":"code","id":"afb79764-c043-4435-93bd-cdb8d5d897d9","metadata":{},"outputs":[],"source":["# Unfreeze the last 4 layers in the base model for fine-tuning\nfor layer in base_model.layers[-4:]:\n    layer.trainable = True\n\n# Re-compile the model with a smaller learning rate\nfrom tensorflow.keras.optimizers import RMSprop\nmodel.compile(\n    loss='categorical_crossentropy',\n    optimizer=RMSprop(learning_rate=1e-5),\n    metrics=['accuracy']\n)\n\n# Continue training\nhistory_fine = model.fit(\n    train_generator,\n    epochs=10,\n    validation_data=val_generator,\n    callbacks=[lr_scheduler, early_stopping]\n)\n"]},{"cell_type":"markdown","id":"8f4a5722-c799-47ec-a322-b6dc6c6b39bc","metadata":{},"outputs":[],"source":["### Explanation:\n","- `for layer in base_model.layers[-4:]`: Unfreezes the last 4 layers to allow fine-tuning.\n","  \n","- `RMSprop(learning_rate=1e-5)`: Optimizer with a lower learning rate to fine-tune carefully without drastic weight changes.\n"]},{"cell_type":"markdown","id":"602930e3-baaa-4e3c-8e64-b31a0011437b","metadata":{},"outputs":[],"source":["<h3>Task 7: Evaluate the model on the test set and display accuracy</h3>\n"]},{"cell_type":"markdown","id":"b0f0903c-631f-4592-a676-86721d59daae","metadata":{},"outputs":[],"source":["**Explanation**: Evaluates the final model on unseen test data to gauge its generalization.\n","\n"]},{"cell_type":"code","id":"9d89934a-ccea-4982-929b-d4eb939b4143","metadata":{},"outputs":[],"source":["# Evaluate on the test set\ntest_loss, test_accuracy = model.evaluate(test_generator)\nprint(f\"Test Accuracy: {test_accuracy:.2f}\")\n"]},{"cell_type":"markdown","id":"4850292a-ef02-4f37-b0d0-1aa10ef6d008","metadata":{},"outputs":[],"source":["### Explanation:\n","\n","- `model.evaluate(test_generator)`: Evaluates the model on the test set and prints accuracy, giving a final measure of model performance.\n"]},{"cell_type":"markdown","id":"d155378a-69ef-477c-aa8a-e200d28dfbbd","metadata":{},"outputs":[],"source":["<h3> Task 8: Visualize training performance with accuracy and loss curves </h3>\n"]},{"cell_type":"markdown","id":"95e6a017-ec41-43e5-970d-06100c112658","metadata":{},"outputs":[],"source":["**Explanation**: Plots the training and validation accuracy and loss to understand the model’s learning progress.\n","\n"]},{"cell_type":"code","id":"0b617839-dfe4-47b2-aef4-a619302cd5e3","metadata":{},"outputs":[],"source":["# Plot accuracy and loss curves\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.plot(history_fine.history['accuracy'], label='Fine-tuned Training Accuracy')\nplt.plot(history_fine.history['val_accuracy'], label='Fine-tuned Validation Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.title('Training and Validation Accuracy')\nplt.grid(True)\nplt.show()\n\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.plot(history_fine.history['loss'], label='Fine-tuned Training Loss')\nplt.plot(history_fine.history['val_loss'], label='Fine-tuned Validation Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.title('Training and Validation Loss')\nplt.grid(True)\nplt.show()"]},{"cell_type":"markdown","id":"715f6b57-d0ee-4e54-800e-da56131ee3cf","metadata":{},"outputs":[],"source":["### Explanation:\n","\n","- `plt.plot`: Plots the accuracy and loss for training and validation over epochs.\n","  \n","- Visual comparison shows if the model is overfitting, underfitting, or learning effectively.\n"]},{"cell_type":"markdown","id":"27c694c8-8785-410a-afbb-224dd5f70fe8","metadata":{},"outputs":[],"source":["<h3>Task 9: Test model predictions on sample images and visualize results</h3>\n"]},{"cell_type":"markdown","id":"bdd6fcb6-5029-4c05-b13f-63837889fea9","metadata":{},"outputs":[],"source":["**Explanation:** Makes predictions on a few test images and displays them with the model's predicted class.\n"]},{"cell_type":"code","id":"56a75c01-fef9-480a-97a8-7f6fb789d7ef","metadata":{},"outputs":[],"source":["import numpy as np\nfrom tensorflow.keras.preprocessing.image import img_to_array, load_img\n\n# Function to visualize a test image with prediction\ndef visualize_prediction(img_path):\n    img = load_img(img_path, target_size=(150, 150))\n    img_array = img_to_array(img) / 255.0\n    img_array = np.expand_dims(img_array, axis=0)\n    \n    prediction = model.predict(img_array)\n    predicted_class = np.argmax(prediction, axis=-1)\n    \n    plt.imshow(img)\n    plt.title(f\"Predicted Class: {predicted_class[0]}\")\n    plt.axis('off')\n    plt.show()\n\n# Test on a few images\nsample_images = [\n    '/path/to/test_image1.jpg',\n    '/path/to/test_image2.jpg',\n    '/path/to/test_image3.jpg'\n]\n\nfor img_path in sample_images:\n    visualize_prediction(img_path)\n"]},{"cell_type":"markdown","id":"6bc2db3b-2179-4cb9-a63f-70a5761512cc","metadata":{},"outputs":[],"source":["### Explanation:\n","\n","- `visualize_prediction`: Loads an image, preprocesses it, predicts its class, and displays it.\n","  \n","- `model.predict(img_array)`: Uses the trained model to make predictions on unseen images.\n"]},{"cell_type":"markdown","id":"a39c9e47-fb67-4131-b507-e986870effa7","metadata":{},"outputs":[],"source":["### Conclusion \n"]},{"cell_type":"markdown","id":"254d3f7b-64da-4913-8d4b-2afd10bb0c19","metadata":{},"outputs":[],"source":["In this lab, you implemented a fruit classification model using transfer learning with VGG16. By fine-tuning and using data augmentation, you developed a robust classifier that can recognize different fruits. This lab demonstrated the efficiency of transfer learning in achieving high accuracy with minimal training data.\n"]},{"cell_type":"markdown","id":"1d39ecbb-cb9c-493b-95c5-1317cde6f871","metadata":{},"outputs":[],"source":["### Author\n","\n","Skills Network\n"]},{"cell_type":"markdown","id":"41a2d42d-b591-4571-8dd4-e39eb91f7150","metadata":{},"outputs":[],"source":["Copyright © IBM Corporation. All rights reserved.\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"},"prev_pub_hash":"c292b10e9c82acc46142dc1761e717d7f01a53423a35388c6a201d36a5042788"},"nbformat":4,"nbformat_minor":4}