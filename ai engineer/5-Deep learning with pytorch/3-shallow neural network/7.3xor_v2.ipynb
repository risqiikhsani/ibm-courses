{"cells":[{"cell_type":"markdown","id":"82b5c6a7-928d-43d3-ba76-dfce93dace2f","metadata":{},"outputs":[],"source":["<p style=\"text-align:center\">\n","    <a href=\"https://skills.network\" target=\"_blank\">\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n","    </a>\n","</p>\n"]},{"cell_type":"markdown","id":"b25e1b64-b056-4af9-a24a-54a9a001fdc4","metadata":{},"outputs":[],"source":["<h1>Practice: Neural Networks with One Hidden Layer: Noisy XOR</h1>\n"]},{"cell_type":"markdown","id":"a51c2f55-e73f-4529-8b7b-cf1d8db2f49b","metadata":{},"outputs":[],"source":["<h2>Objective</h2><ul><li> How to create a neural network model with multiple neurons.</li></ul> \n"]},{"cell_type":"markdown","id":"d7c4f8f5-1395-4538-9623-8a442d528741","metadata":{},"outputs":[],"source":["<h2>Table of Contents</h2>\n","<p>In this lab, you will see how many neurons it takes to classify noisy XOR data with one hidden layer neural network.</p>\n","\n","<ul>\n","    <li><a href=\"#Model\">Neural Network Module and Training Function</a></li>\n","    <li><a href=\"#Makeup_Data\">Make Some Data</a></li>\n","    <li><a href=\"#One\">One Neuron</a></li>\n","    <li><a href=\"#Two\">Two Neurons</a></li>\n","    <li><a href=\"#Three\">Three Neurons</a></li>\n","</ul>\n","<p>Estimated Time Needed: <strong>25 min</strong></p>\n","<hr>\n"]},{"cell_type":"markdown","id":"586b1e9e-7932-41dd-b7c1-cbf29b185f6b","metadata":{},"outputs":[],"source":["<h2>Preparation</h2>\n"]},{"cell_type":"markdown","id":"65f56feb-7ca7-4fe6-8827-47892cb74e9c","metadata":{},"outputs":[],"source":["We'll need the following libraries\n"]},{"cell_type":"code","id":"aea44372-9d74-4fe0-9306-001f54e90280","metadata":{},"outputs":[],"source":["# Import the libraries we need for this lab\n\n\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt \nfrom matplotlib.colors import ListedColormap\nfrom torch.utils.data import Dataset, DataLoader"]},{"cell_type":"markdown","id":"bffdaf6a-9b65-417a-94f3-0f551aacc3c3","metadata":{},"outputs":[],"source":["Use the following function to plot the data: \n"]},{"cell_type":"code","id":"216fd744-6709-4c60-a37d-7bb40c4710bf","metadata":{},"outputs":[],"source":["# Plot the data\n\ndef plot_decision_regions_2class(model,data_set):\n    cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#00AAFF'])\n    cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#00AAFF'])\n    X = data_set.x.numpy()\n    y = data_set.y.numpy()\n    h = .02\n    x_min, x_max = X[:, 0].min() - 0.1 , X[:, 0].max() + 0.1 \n    y_min, y_max = X[:, 1].min() - 0.1 , X[:, 1].max() + 0.1 \n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n    XX = torch.Tensor(np.c_[xx.ravel(), yy.ravel()])\n\n    yhat = np.logical_not((model(XX)[:, 0] > 0.5).numpy()).reshape(xx.shape)\n    plt.pcolormesh(xx, yy, yhat, cmap=cmap_light)\n    plt.plot(X[y[:, 0] == 0, 0], X[y[:, 0] == 0, 1], 'o', label='y=0')\n    plt.plot(X[y[:, 0] == 1, 0], X[y[:, 0] == 1, 1], 'ro', label='y=1')\n    plt.title(\"decision region\")\n    plt.legend()"]},{"cell_type":"markdown","id":"d0f7ebf9-d557-4f95-af64-996462d78be3","metadata":{},"outputs":[],"source":["Use the following function to calculate accuracy: \n"]},{"cell_type":"code","id":"ebbcead3-3d4b-45ec-b329-7f1ebf7dbce9","metadata":{},"outputs":[],"source":["# Calculate the accuracy\n\ndef accuracy(model, data_set):\n    return np.mean(data_set.y.view(-1).numpy() == (model(data_set.x)[:, 0] > 0.5).numpy())"]},{"cell_type":"markdown","id":"e56be5f3-f788-466f-9240-5fbdab593c7b","metadata":{},"outputs":[],"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"088ff611-64e2-4db1-8fab-c95124dec544","metadata":{},"outputs":[],"source":["<a name=\"Model\"><h2 id=\"Model\">Neural Network Module and Training Function</h2></a>\n"]},{"cell_type":"markdown","id":"0b67039c-4041-4b9c-a87d-90fcd6b3483d","metadata":{},"outputs":[],"source":["Define the neural network module or class: \n"]},{"cell_type":"code","id":"fdb76512-0a45-4fde-b860-b3cb7fa3424c","metadata":{},"outputs":[],"source":["# Define the class Net with one hidden layer \n\nclass Net(nn.Module):\n    \n    # Constructor\n    def __init__(self, D_in, H, D_out):\n        super(Net, self).__init__()\n        #hidden layer \n        self.linear1 = nn.Linear(D_in, H)\n        #output layer \n        self.linear2 = nn.Linear(H, D_out)\n\n    # Prediction    \n    def forward(self, x):\n        x = torch.sigmoid(self.linear1(x))  \n        x = torch.sigmoid(self.linear2(x))\n        return x"]},{"cell_type":"markdown","id":"8f377e3c-aa4b-4413-babc-74a51310dee9","metadata":{},"outputs":[],"source":["Define a function to train the model: \n"]},{"cell_type":"code","id":"635ceb80-ea9b-4bd5-a492-ef029f01e746","metadata":{},"outputs":[],"source":["# Define the train model\n\ndef train(data_set, model, criterion, train_loader, optimizer, epochs=5):\n    COST = []\n    ACC = []\n    for epoch in range(epochs):\n        total=0\n        for x, y in train_loader:\n            optimizer.zero_grad()\n            yhat = model(x)\n            loss = criterion(yhat, y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            #cumulative loss \n            total+=loss.item()\n        ACC.append(accuracy(model, data_set))\n        COST.append(total)\n        \n    fig, ax1 = plt.subplots()\n    color = 'tab:red'\n    ax1.plot(COST, color=color)\n    ax1.set_xlabel('epoch', color=color)\n    ax1.set_ylabel('total loss', color=color)\n    ax1.tick_params(axis='y', color=color)\n    \n    ax2 = ax1.twinx()  \n    color = 'tab:blue'\n    ax2.set_ylabel('accuracy', color=color)  # we already handled the x-label with ax1\n    ax2.plot(ACC, color=color)\n    ax2.tick_params(axis='y', color=color)\n    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n    \n    plt.show()\n\n    return COST"]},{"cell_type":"markdown","id":"cfc1494c-2b44-4b79-954d-e06b37e1fe91","metadata":{},"outputs":[],"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"7d01a4c8-22fd-4ec8-8ec1-bbea93f6d622","metadata":{},"outputs":[],"source":["<a name=\"Makeup_Data\"><h2 id=\"Makeup_Data\">Make Some Data</h2></a>\n"]},{"cell_type":"markdown","id":"c0b45125-b416-4937-918f-d7fdb821cd01","metadata":{},"outputs":[],"source":["Dataset class:\n"]},{"cell_type":"code","id":"5e0cf35d-28fa-469c-9c1b-d470e9233b70","metadata":{},"outputs":[],"source":["# Define the class XOR_Data\n\nclass XOR_Data(Dataset):\n    \n    # Constructor\n    def __init__(self, N_s=100):\n        self.x = torch.zeros((N_s, 2))\n        self.y = torch.zeros((N_s, 1))\n        for i in range(N_s // 4):\n            self.x[i, :] = torch.Tensor([0.0, 0.0]) \n            self.y[i, 0] = torch.Tensor([0.0])\n\n            self.x[i + N_s // 4, :] = torch.Tensor([0.0, 1.0])\n            self.y[i + N_s // 4, 0] = torch.Tensor([1.0])\n    \n            self.x[i + N_s // 2, :] = torch.Tensor([1.0, 0.0])\n            self.y[i + N_s // 2, 0] = torch.Tensor([1.0])\n    \n            self.x[i + 3 * N_s // 4, :] = torch.Tensor([1.0, 1.0])\n            self.y[i + 3 * N_s // 4, 0] = torch.Tensor([0.0])\n\n            self.x = self.x + 0.01 * torch.randn((N_s, 2))\n        self.len = N_s\n\n    # Getter\n    def __getitem__(self, index):    \n        return self.x[index],self.y[index]\n    \n    # Get Length\n    def __len__(self):\n        return self.len\n    \n    # Plot the data\n    def plot_stuff(self):\n        plt.plot(self.x[self.y[:, 0] == 0, 0].numpy(), self.x[self.y[:, 0] == 0, 1].numpy(), 'o', label=\"y=0\")\n        plt.plot(self.x[self.y[:, 0] == 1, 0].numpy(), self.x[self.y[:, 0] == 1, 1].numpy(), 'ro', label=\"y=1\")\n        plt.legend()"]},{"cell_type":"markdown","id":"63d174e8-2117-4896-a314-b725c66a60a3","metadata":{},"outputs":[],"source":["Dataset object:\n"]},{"cell_type":"code","id":"e873bcfb-4dd5-4d03-85c5-cc6308a860b3","metadata":{},"outputs":[],"source":["# Create dataset object\n\ndata_set = XOR_Data()\ndata_set.plot_stuff()"]},{"cell_type":"markdown","id":"1451ca3a-4df4-486d-af26-811803621e03","metadata":{},"outputs":[],"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"e2e31579-e37d-4039-b8a3-cac94439be44","metadata":{},"outputs":[],"source":["<a name=\"One\"><h2 id=\"One\">One Neuron</h2></a>\n"]},{"cell_type":"markdown","id":"4905eb54-ab9d-44a1-9321-d2c624ec2845","metadata":{},"outputs":[],"source":["<h3>Try</h3>\n"]},{"cell_type":"markdown","id":"990cd537-9d32-4fe4-9267-f0ee8ea15f49","metadata":{},"outputs":[],"source":["Create a neural network <code>model</code> with one neuron. Then, use the following code to train it:\n"]},{"cell_type":"code","id":"bedb9180-da5a-4a1c-a156-75d9011eb04b","metadata":{},"outputs":[],"source":["# Practice: create a model with one neuron\n\n# Type your code here"]},{"cell_type":"markdown","id":"f4557ffb-562d-48f1-b41a-08161451e08a","metadata":{},"outputs":[],"source":["Double-click <b>here</b> for the solution.\n","\n","<!-- \n","model = Net(2, 1, 1)\n","-->\n"]},{"cell_type":"code","id":"7947f114-04a1-4fbf-8ef7-1fee8817073c","metadata":{},"outputs":[],"source":["# Train the model\n\nlearning_rate = 0.001\ncriterion = nn.BCELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\ntrain_loader = DataLoader(dataset=data_set, batch_size=1)\nLOSS12 = train(data_set, model, criterion, train_loader, optimizer, epochs=500)\nplot_decision_regions_2class(model, data_set)"]},{"cell_type":"markdown","id":"886e21bd-8c45-4f69-8305-52d54e3317b2","metadata":{},"outputs":[],"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"d25602a8-27d2-4af4-a5ea-093beb9e055e","metadata":{},"outputs":[],"source":["<a name=\"Two\"><h2 id=\"Two\">Two Neurons</h2></a>\n"]},{"cell_type":"markdown","id":"6a6ab628-156e-41da-9faf-e809a413dbef","metadata":{},"outputs":[],"source":["<h3>Try</h3>\n"]},{"cell_type":"markdown","id":"bf9609ed-41d6-45ee-b41f-162d9eb2c165","metadata":{},"outputs":[],"source":["Create a neural network <code>model</code> with two neurons. Then, use the following code to train it:\n"]},{"cell_type":"code","id":"6df8c39a-bce8-4b5e-81a3-604a47ca919a","metadata":{},"outputs":[],"source":["# Practice: create a model with two neuron\n\n# Type your code here"]},{"cell_type":"markdown","id":"bf35af45-6144-4fa5-a0f5-7a4bb796e748","metadata":{},"outputs":[],"source":["Double-click <b>here</b> for the solution.\n","\n","<!-- \n","model = Net(2, 2, 1)\n","-->\n"]},{"cell_type":"code","id":"94e7b670-9929-4d10-bec1-3016012bd40f","metadata":{},"outputs":[],"source":["# Train the model\n\nlearning_rate = 0.1\ncriterion = nn.BCELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\ntrain_loader = DataLoader(dataset=data_set, batch_size=1)\nLOSS12 = train(data_set, model, criterion, train_loader, optimizer, epochs=500)\nplot_decision_regions_2class(model, data_set)"]},{"cell_type":"markdown","id":"cbb3bde7-e4d0-40e6-8630-e3bfb0dfcad4","metadata":{},"outputs":[],"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"b9507730-ca33-47eb-bf68-7f6bfdb2c870","metadata":{},"outputs":[],"source":["<a name=\"Three\"><h2 id=\"Three\">Three Neurons</h2></a>\n"]},{"cell_type":"markdown","id":"f4d27dbe-c99e-45d0-9eb3-a2b5c1f93492","metadata":{},"outputs":[],"source":["<h3>Try</h3>\n"]},{"cell_type":"markdown","id":"f9298f82-50be-4855-a4c6-c2f89313884d","metadata":{},"outputs":[],"source":["Create a neural network <code>model</code> with three neurons. Then, use the following code to train it:\n"]},{"cell_type":"code","id":"68a09cce-a35f-47ce-aaa6-258389a45278","metadata":{},"outputs":[],"source":["# Practice: create a model with two neuron\n\n# Type your code here"]},{"cell_type":"markdown","id":"57326e96-7765-431e-831c-09d55858a83f","metadata":{},"outputs":[],"source":["Double-click <b>here</b> for the solution.\n","\n","<!-- \n","model = Net(2, 3, 1)\n","-->\n"]},{"cell_type":"code","id":"65cc47de-3add-43ce-9925-4d3770b6a4ff","metadata":{},"outputs":[],"source":["# Train the model\n\nlearning_rate = 0.1\ncriterion = nn.BCELoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\ntrain_loader = DataLoader(dataset=data_set, batch_size=1)\nLOSS12 = train(data_set, model, criterion, train_loader, optimizer, epochs=500)\nplot_decision_regions_2class(model, data_set)\n"]},{"cell_type":"markdown","id":"9c5f7f70-14b8-421b-bacf-e70f40e85355","metadata":{},"outputs":[],"source":["\n","\n","<a href=\"https://dataplatform.cloud.ibm.com/registration/stepone?utm_source=skills_network&utm_content=in_lab_content_link&utm_id=Lab-IBMDeveloperSkillsNetwork-DL0110EN-SkillsNetwork&context=cpdaas&apps=data_science_experience%2Cwatson_machine_learning\"><img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DL0110EN-SkillsNetwork/Template/module%201/images/Watson_Studio.png\"></a>\n"]},{"cell_type":"markdown","id":"50873f00-5fcf-41e3-bcb7-016e9dc279a7","metadata":{},"outputs":[],"source":["<!--Empty Space for separating topics-->\n"]},{"cell_type":"markdown","id":"4c853d98-c3b0-48f0-9f68-27d272001741","metadata":{},"outputs":[],"source":["<h2>About the Authors:</h2> \n","\n","<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD. \n"]},{"cell_type":"markdown","id":"968e7244-bb15-45e3-a3f5-0808351ac716","metadata":{},"outputs":[],"source":["Other contributors: <a href=\"https://www.linkedin.com/in/michelleccarey/\">Michelle Carey</a>, <a href=\"www.linkedin.com/in/jiahui-mavis-zhou-a4537814a\">Mavis Zhou</a>\n"]},{"cell_type":"markdown","id":"5692a3bd-1444-4c9c-bd14-181a09ee2b0a","metadata":{},"outputs":[],"source":["<!--\n","## Change Log\n","\n","|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n","|---|---|---|---|\n","| 2020-09-23  | 2.0  | Shubham  |  Migrated Lab to Markdown and added to course repo in GitLab |\n","-->\n"]},{"cell_type":"markdown","id":"00445146-35a5-4d88-9892-72ee5e64796a","metadata":{},"outputs":[],"source":["<hr>\n"]},{"cell_type":"markdown","id":"91e07609-8a47-43f8-9393-f89114cbe760","metadata":{},"outputs":[],"source":["\n","## <h3 align=\"center\"> &#169; IBM Corporation. All rights reserved. <h3/>\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"prev_pub_hash":"ace4f5a580d036e0a466fa0d483922c6b6b57c5be1859f6243536692b847d4fd"},"nbformat":4,"nbformat_minor":4}